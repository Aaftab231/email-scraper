# ğŸ“¬ Email Scraper

An ethical command-line tool to extract emails from websites using multithreading, robots.txt compliance, and filtering options.

---

## ğŸš€ Features

- âœ… Multithreaded crawling
- âœ… Robots.txt with `crawl-delay`
- âœ… Scope restriction and URL deduplication
- âœ… User-Agent rotation and rate limiting
- âœ… Keyword-based email filtering
- âœ… Dry-run preview mode
- âœ… Colorized CLI and verbose logging
- âœ… YAML config support
- âœ… Export results to TXT, CSV, or JSON

---

## ğŸ“¦ Installation

```bash
# Clone and install locally
git clone https://github.com/Aaftab231/email-scraper.git
cd email-scraper
pip install .
```

---

## âš™ï¸ Usage

```bash
# Basic usage
email-scraper https://example.com

# With keyword filtering
email-scraper https://example.com -k admin,hr

# Using config file
email-scraper --config config.yaml

# Save output as CSV or JSON
email-scraper https://example.com -o output.csv -f csv
```

---

## ğŸ”§ Arguments

| Flag           | Description                               |
|----------------|-------------------------------------------|
| `url`          | Starting URL to crawl                     |
| `--max`        | Max pages to crawl                        |
| `--output`     | Output filename                           |
| `--format`     | Output format: `txt`, `csv`, or `json`    |
| `--threads`    | Number of threads (default: 5)            |
| `--keywords`   | Comma-separated email filter keywords     |
| `--dry-run`    | Preview crawl plan without making requests|
| `--verbose`    | Show verbose, colorized output            |
| `--scope-only` | Stay within base domain only              |
| `--config`     | Path to YAML config file                  |

---

## ğŸ§ª Example with Config File

```yaml
# config.yaml
url: "https://example.com"
max: 100
output: "results.json"
format: "json"
threads: 10
keywords:
  - admin
  - hr
  - support
```

Run with:
```bash
email-scraper --config config.yaml
```

---

## ğŸ“ Project Structure

```
email-scraper-pro/
â”œâ”€â”€ email_scraper.py         # Main CLI tool
â”œâ”€â”€ setup.py                 # For pip installation
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ README.md                # Project documentation
â”œâ”€â”€ config.yaml              # Sample configuration
â””â”€â”€ .gitignore               # Optional git ignore file
```

---

## ğŸ›  Development

Install dependencies in a virtual environment:
```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

Run locally:
```bash
python email_scraper.py https://example.com -t 5 -m 50
```

---

## ğŸ“ License

This project is licensed under the MIT License. See the `LICENSE` file for details.

---

## ğŸ’¡ Customization

You may customize this tool according to your needs. Feel free to use, modify, or extend it for personal, educational, or professional purposes.

---

## ğŸ‘¨â€ğŸ’» Author

**** â€” Programmer & Python Developer  

